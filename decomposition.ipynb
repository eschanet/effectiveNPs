{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import simplify # need a local dev version for this\n",
    "\n",
    "pyhf.set_backend(pyhf.tensorlib, \"minuit\")\n",
    "spec = json.load(open(\"BkgOnly.json\", \"r\"))\n",
    "\n",
    "ws = pyhf.Workspace(spec)\n",
    "model = ws.model(modifier_settings = {\"normsys\": {\"interpcode\": \"code4\"},\"histosys\": {\"interpcode\": \"code4p\"},})\n",
    "data = ws.data(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run fit\n",
    "fit_result = simplify.fitter.fit(model, data)\n",
    "\n",
    "# uncertainties for later\n",
    "total_stdev_model = simplify.model_tools.calculate_stdev(\n",
    "    model, fit_result.bestfit, fit_result.uncertainty, fit_result.corr_mat\n",
    ")\n",
    "\n",
    "# correlation matrix for now\n",
    "plt = simplify.plot.correlation_matrix(fit_result,\"\",pruning_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVals, eigVecs = np.linalg.eig(fit_result.corr_mat) # real symmetric matrix, always diagonalisable, yeay\n",
    "\n",
    "# eigendecomposition: A = Q*Lambda*Q^T, where Lambda is diag(eVals), Q is matrix with eVecs as columns\n",
    "eigVals_diag = np.diag(eigVals)\n",
    "eigVecs.dot(eigVals).dot(eigVecs.T) # this gives us the original corrmatrix back, right?\n",
    "\n",
    "# May want to sort them?\n",
    "# _order = np.argsort(eigVals)\n",
    "# eigVals[_order]\n",
    "\n",
    "m = np.linalg.inv(eigVals_diag.dot(eigVecs.T))\n",
    "\n",
    "#this should be a unit matrix\n",
    "np.testing.assert_allclose(\n",
    "    eigVals_diag.dot(eigVecs.T).dot(m),\n",
    "    np.identity(len(fit_result.labels)),\n",
    "    atol=1e-12\n",
    ")\n",
    "\n",
    "# this should give us back the matrix with EV as columns\n",
    "np.testing.assert_allclose(\n",
    "    fit_result.corr_mat.dot(m),\n",
    "    eigVecs,\n",
    "    atol=1e-3 # why is this so bad?\n",
    ")\n",
    "\n",
    "bestfit_eigenspace = fit_result.bestfit.dot(m)\n",
    "uncertainty_eigenspace = np.sqrt(np.square(fit_result.uncertainty).dot(np.abs(m)))\n",
    "\n",
    "# Sometimes nice to see what the actual values are\n",
    "# for l, b in zip(fit_result.labels, fit_result.bestfit):\n",
    "#     print(l,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def matrix(\n",
    "    values,\n",
    "    l,\n",
    "    output_name,\n",
    "    pruning_threshold,\n",
    "    pruning_vals,\n",
    "    **kwargs: int,\n",
    ") -> None:\n",
    "\n",
    "    # pruning all entries below threshold with mask\n",
    "    below_threshold = np.where(\n",
    "        np.abs(pruning_vals) < pruning_threshold, True, False\n",
    "    )\n",
    "    all_below_threshold = np.all(below_threshold, axis=0)\n",
    "\n",
    "    delete_indices = np.where(all_below_threshold)\n",
    "    vals = np.delete(\n",
    "        np.delete(values, delete_indices, axis=1), delete_indices, axis=0\n",
    "    )\n",
    "    figure_path = pathlib.Path(\"\") / output_name\n",
    "\n",
    "    # borrowing correlation matrix code for this\n",
    "    simplify.helpers.plotting.correlation_matrix(vals, np.delete(l, delete_indices), figure_path, **kwargs)\n",
    "\n",
    "# generate new fit result object for hacking simplify plotting \n",
    "labels = [f\"Effective NP {i+1}\" for i in range(len(bestfit_eigenspace))]\n",
    "\n",
    "eigenvalue_matrix = matrix(eigVals_diag, labels, \"eigenvalue_matrix.pdf\", pruning_threshold=1.1, pruning_vals=eigVals_diag, **{'vmin':0.1, 'vmax':4, 'cmap':'Blues'})\n",
    "eigenvector_matrix = matrix(eigVecs, labels, \"eigenvector_matrix.pdf\", pruning_threshold=1.1, pruning_vals=eigVals_diag, **{'vmin':-1, 'vmax':1, 'cmap':'RdBu', 'tmin':0.0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward1 as ak\n",
    "def calculate_uncertainty(\n",
    "    model,\n",
    "    parameters,\n",
    "    uncertainty,\n",
    "    corr_mat,\n",
    "):\n",
    "\n",
    "    # indices where to split to separate all bins into regions\n",
    "    region_split_indices = simplify.model_tools._get_channel_boundary_indices(model)\n",
    "\n",
    "    up_variations = []\n",
    "    down_variations = []\n",
    "    for i_par in range(model.config.npars):\n",
    "        # central parameter values, but one parameter varied within uncertainties\n",
    "        up_pars = parameters.copy()\n",
    "        up_pars[i_par] += uncertainty[i_par]\n",
    "        down_pars = parameters.copy()\n",
    "        down_pars[i_par] -= uncertainty[i_par]\n",
    "\n",
    "        # total model distribution with this parameter varied up\n",
    "        up_combined = model.expected_data(up_pars, include_auxdata=False)\n",
    "        up_yields = np.split(up_combined, region_split_indices)\n",
    "        up_variations.append(up_yields)\n",
    "\n",
    "        # total model distribution with this parameter varied down\n",
    "        down_combined = model.expected_data(down_pars, include_auxdata=False)\n",
    "        down_yields = np.split(down_combined, region_split_indices)\n",
    "        down_variations.append(down_yields)\n",
    "\n",
    "    # convert to awkward arrays for further processing\n",
    "    up_variations = ak.from_iter(up_variations)\n",
    "    down_variations = ak.from_iter(down_variations)\n",
    "\n",
    "    # total variance, indices are: channel, bin\n",
    "    total_variance_list = [\n",
    "        np.zeros(shape=(model.config.channel_nbins[ch])) for ch in model.config.channels\n",
    "    ]  # list of arrays, each array has as many entries as there are bins\n",
    "    total_variance = ak.from_iter(total_variance_list)\n",
    "\n",
    "    # loop over parameters to sum up total variance\n",
    "    # first do the diagonal of the correlation matrix\n",
    "    for i_par in range(model.config.npars):\n",
    "        symmetric_uncertainty = (up_variations[i_par] - down_variations[i_par]) / 2\n",
    "        total_variance = total_variance + symmetric_uncertainty ** 2\n",
    "\n",
    "    labels = simplify.model_tools.get_parameter_names(model)\n",
    "\n",
    "    # convert to standard deviation\n",
    "    total_stdev = np.sqrt(total_variance)\n",
    "    return total_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uncs_eigenspace = calculate_uncertainty(model,bestfit_eigenspace,uncertainty_eigenspace,np.identity(len(uncertainty_eigenspace)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('simplify-dev': conda)",
   "metadata": {
    "interpreter": {
     "hash": "51732e4e8a73283ab5831821176c0127e80d2da7e019bb469f379d2faeba9394"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}